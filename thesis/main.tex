\documentclass[bachelor,english]{infothesis}
% possible types: bachelor, master, zula (seminar, practical)
% Für Seminararbeiten und Praktikumsberichte die Vorlage my-seminar-praktikum.tex verwenden!
% possible languages: english, german

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage{svg}
\usepackage{pythonhighlight}
\usepackage{longtable}

\graphicspath{{figures/}}




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%% Bitte nur ab hier Änderungen vornehmen %%%%%%%%%%%%%%%%%%%%%

\title{Reinforcement Learning for Control of Flying Drones} 

\author{Johannes M. Tölle} 

\submissiondate{06. 09. 2023} 

\supervisors{% Geben Sie die Namen aller Betreuer ab, getrennt durch das Makro '\and'
%Prof.\ Dr.\ Günther Waxenegger-Wilfing \and
%Prof.\ Dr-Ing.\ Sergio Montenegro \and
Prof.\ Dr.\ Carlo D'Eramo
} 

\renewcommand{\contentsname}{Table of Contents}
\renewcommand{\listfigurename}{List of Figures}
\renewcommand{\listtablename}{List of Tables}
%\renewcommand{\listalgorithmname}{List of Algorithms}

\newenvironment{declaration}
{\chapter*{Declaration}}
{\clearpage}


\begin{document}
\pagenumbering{roman}
	
\begin{declaration}
	I certify that I have authored this thesis, including all attached materials,
	constantly and without the use of any other aids than those specified.\\
	All passages taken literally or analogously from published or unpublished works
	are clearly identified as such in each individual case, stating the source.\\
	The work has not yet been submitted in the same or a similar form as a thesis.\\
	I am aware that violations of this declaration and deliberate deception may lead to
	a grade of 5.0.\\
	\vspace*{12cm}\\
	Würzurburg, \today 
	\hspace*{\fill}\begin{tabular}{@{}l@{}}\hline
	\makebox[4cm]{Johannes M. Tölle}
	\end{tabular}
\end{declaration}

\tableofcontents
\listoffigures
\listoftables
\listofalgorithms

\newpage

\begin{abstract}
	content...
\end{abstract}




%\thesistableofcontents




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\setcounter{page}{1}
\pagenumbering{arabic}
\chapter{Introduction}
	\input{content/intro.tex}

\chapter{Basics}
	\input{content/basics.tex}

%\chapter{State of the Art Algorithms}
%	\input{content/sota.tex}
	
\chapter{Flight-Control Concept}
	\input{content/concept.tex}

\chapter{Implementation}
	\input{content/scripts.tex}

%\chapter{Evaluation Tools}
%	\input{content/evalsetup.tex}

\chapter{Evaluation}
	\input{content/evaluation.tex}

\chapter{Conclusion \& Future Work}
	\input{content/conclusion.tex}

%\chapter{Appendix}
%	\input{content/appendix.tex}
	
\chapter*{List of Symbols}
\addcontentsline{toc}{chapter}{List of Symbols}

\begin{description}
	\item $\Theta$ \dotfill Roll Euler Angle
	\item $\phi$  \dotfill Pitch Euler Angle
	\item $\psi$ \dotfill Yaw Euler Angle
	\item $M_i \qquad i \in [1,4]$ \dotfill Motor of a Quadrocopter
	\item $\tilde{f}$ \dotfill Upward Thrust of a UAV
	\item $\omega_i \qquad i \in [1,4]$ \dotfill  Rotational speed of a propeller of a Quadrocopter
	\item $\omega_i^* \qquad i \in [1,4]$ \dotfill Changed Rotational speed 
	\item $b$ \dotfill Quadrocopter constant
	\item $u_{\Theta}, u_{\phi}, u_{\psi}$ \dotfill Rotational movement
	\item $p_{3D}$ \dotfill Pose in 3D space
	\item $x_p, y_p, z_p$ \dotfill Coordinates in 3D space
	\item $F$ \dotfill Upward Thrust Force
	\item $G$ \dotfill Gravitational Force
	\\
	\item $g$ \dotfill Mission Goal
	\item $a$ \dotfill Attitude
	\item $a^*$ \dotfill Estimated Attitude
	\item $e_a$ \dotfill Attitude Error
	\item $S$ \dotfill Set of Motor Signals
	\item $p$ \dotfill Estimated Pose
	\item $p_{3D}^*$ \dotfill Estimated 3D Pose
	\item $(K_p, K_i, K_d), (K, T_n, T_v)$  \dotfill Tuple of PID controll gains
	\item $u(t)$ \dotfill Control Signal
	\item $e(t)$ \dotfill Error Signal
	\item $\tilde{T}$ \dotfill Sampling Time Period
	\item $f'$ \dotfill Throttle Coefficient
	\item $m_{i,\Theta} , m_{i, \phi}, m_{i, \psi}$ \dotfill Mixer Values of the Motors
	\item $\Lambda$ \dotfill Set of Waypoints
	\item $\lambda_i \qquad i \in [0...n]$ \dotfill Waypoint
	\\
	\item $S$ \dotfill Set of states
	\item $A$ \dotfill Set of actions
	\item $R$ \dotfill Reward function
	\item $P$ \dotfill State Transition probability
	\item $p_0$ \dotfill Starting State Distribution
	\item $s_t$ \dotfill Observed State at timestep $t$
	\item $s_t^*$ \dotfill Real State at timestep $t$
	\item $a_t$ \dotfill Action at timestep $t$
	\item $r_t$ \dotfill Reward at timestep $t$
	\item $\pi$ \dotfill Policy
	\item $\pi^*$ \dotfill Optimal Policy
	\item $\tau$ \dotfill Trajectory
	\item $T$ \dotfill Amount of steps in a trajectory
	\item $\gamma$ \dotfill Discount factor
	\item $V^{\pi}(s)$ \dotfill Value Function under a policy
	\item $V^*(s)$ \dotfill Optimal Value Function
	\item $Q^{\pi} (s,a)$ \dotfill Q Function under a policy
	\item $Q^*(s,a)$ \dotfill Optimal Q Function
	\item $x_i$ \dotfill Input to a NN
	\item $w_i$ \dotfill Weight of edge in a NN
	\item $g()$ \dotfill Activation Function
	\item $\Theta$ \dotfill Policy Parameters
	\item $\phi$ \dotfill Value Function Parameters in PPO
	\item $L(s_t, a_t, \Theta_{old}, \Theta)$ \dotfill Policy Loss in PPO
	\item $g(\epsilon, A)$ \dotfill Surrogate Objective
	\item $\epsilon$ \dotfill Learning Rate
	\item $A$ \dotfill Advantage Function
	\item $\alpha$ \dotfill Trade-Off coefficient in SAC
	\item $H$ \dotfill Entropy
	\item $\mathcal{D}$ \dotfill Replay Buffer
	\item $L(\phi_i, \mathcal{D})$ \dotfill Loss Function in SAC
	\item $d$ \dotfill Done Value
	\item $y(r, s', d)$ \dotfill Target in SAC
	\item $\tilde{a}$ \dotfill Next Action sampled from the policy
	\item $\mathcal{B}$ \dotfill Batch of Transitions
	\item $\rho$ \dotfill Polyak averging hyperparameter
	\\
	\item $\overrightarrow{g}$ \dotfill Goal Vector
	\item $g_x, g_y, g_z$ \dotfill Goal Coordinates
	\item $p$ \dotfill Position Tupel
	\item $\overrightarrow{p_t}$ \dotfill Position Vector at time step $t$
	\item $\dot{p_i} \qquad i \in \{x,y,z\}$ \dotfill Linear Velocities
	\item $\dot{\Theta}, \dot{\phi}, \dot{\psi}$ \dotfill Angular Velocities
	\item $\sigma$ \dotfill Sensor Values
	\item $f_s$ \dotfill Simulation Frequency
	\item $\aleph$ \dotfill Number of physics steps within a step
	\item $\omega_w$ \dotfill Wind Force Bound
	\item $T$ \dotfill Episode length
	\item $R$ \dotfill Radius
	\item $\overrightarrow{W}$ \dotfill Wind Force Vector
	\item $\overrightarrow{p_0}$ \dotfill Starting State Vector
	\item $z_{min}$ \dotfill Minimum height of Coordinate Frame
	\item $\daleth$ \dotfill Observation Space
	\item $\daleth_t$ \dotfill Observation at time step $t$
	\item $v_i \qquad i \in [0,11]$ \dotfill Predefined Clipping Values
	\item $dist_t$ \dotfill Distance at time step $t$
	\item $t_s$ \dotfill SImulation time step
	\item $r_{opt}$ \dotfill Optimal Reward
	\item $f_c$ \dotfill Control Frequency
	\item $m$ \dotfill Mass of UAV
	\\
	\item $\xi$ \dotfill Set of parsed agruments to a script
	\item $\tilde{\lambda}$ \dotfill Set of environment arguments
	\item $\nu$ \dotfill Amount of parallel training environments
	\item $t_{total}$ \dotfill Training steps
	\item $\iota$ \dotfill Parsed load parameter
	\item $\zeta$ \dotfill Parsed curriculum parameter
	\item  $\epsilon_t$ \dotfill Training environment
	\item $\epsilon_e$ \dotfill Evaluation environment
	\item $\epsilon$ \dotfill Environment
	\item $R_{max}$ \dotfill Maximum radius in LCL
	\item $\tilde{\rho}$ \dotfill Parsed gui parameter
	\item $t^*$ \dotfill Real time
	\item  $t_{sim}$ \dotfill Simulation time
	\item $\Sigma$ \dotfill Threshold of EvalWriter
	\item $\gimel$ \dotfill Evaluation episodes
	\item $\beth$ \dotfill Time Rate
	\item $\mu_r$ \dotfill Mean reward
	\item $\sigma_r$ \dotfill Std reward
\end{description}

\chapter*{List of Abbreviations}
\addcontentsline{toc}{chapter}{List of Abbreviations}

\begin{description}
	\item DOF \dotfill Degree of Freedom
	\item FC \dotfill Flight controller
	\item PID controller \dotfill Proportional-Integral-Differential controller
	\item RL \dotfill Reinforcement Learning
	\item NLP \dotfill Natural Language Processing
	\item ML \dotfill Machine Learning
	\item MDP \dotfill Markov Decision Process
	\item NN \dotfill Neural Network
	\item PPO \dotfill Proximal Policy Optimization
	\item SAC \dotfill Soft Actor-Critic
\end{description}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\clearpage
\bibliographystyle{mybabalpha-fl}
\bibliography{mybib}


\end{document}
