
@article{koch2019reinforcement,
	title={Reinforcement learning for UAV attitude control},
	author={Koch, William and Mancuso, Renato and West, Richard and Bestavros, Azer},
	journal={ACM Transactions on Cyber-Physical Systems},
	volume={3},
	number={2},
	pages={22},
	year={2019},
	publisher={ACM}
}

@inproceedings{shi2022deep,
	title={Deep Kalman-based Trajectory Estimation of Moving Target from Satellite Images},
	author={Shi, Zhong and Zhao, Fanyu and Wang, Xin and Jin, Zhonghe},
	booktitle={2022 IEEE 10th Joint International Information Technology and Artificial Intelligence Conference (ITAIC)},
	volume={10},
	pages={71--75},
	year={2022},
	organization={IEEE}
}

@article{nelson2007vector,
	title={Vector field path following for miniature air vehicles},
	author={Nelson, Derek R and Barber, D Blake and McLain, Timothy W and Beard, Randal W},
	journal={IEEE Transactions on Robotics},
	volume={23},
	number={3},
	pages={519--529},
	year={2007},
	publisher={IEEE}
}

@INPROCEEDINGS{6669680,
	author={Sujit, P.B. and Saripalli, Srikanth and Sousa, J.B.},
	booktitle={2013 European Control Conference (ECC)}, 
	title={An evaluation of UAV path following algorithms}, 
	year={2013},
	volume={},
	number={},
	pages={3332-3337},
	doi={10.23919/ECC.2013.6669680}}

@Book{TT,
	author={A.M. Turing},
	booktitle={Computing Machinery and Intelligence},
	title={The Imitation Game},
	year={1950},
	chapter={Chapter 1}}

@Book{NN,
	author={Dr. Joachim Steinwendler, Dr. Roland Schwaiger},
	title={Neuronale Netze programmieren in Python},
	year={2020},
	publisher={Rheinwerk Verlag}}
	

@InProceedings{pmlr-v120-yang20a,
	title = 	 {A Theoretical Analysis of Deep Q-Learning},
	author =       {Fan, Jianqing and Wang, Zhaoran and Xie, Yuchen and Yang, Zhuoran},
	booktitle = 	 {Proceedings of the 2nd Conference on Learning for Dynamics and Control},
	pages = 	 {486--489},
	year = 	 {2020},
	editor = 	 {Bayen, Alexandre M. and Jadbabaie, Ali and Pappas, George and Parrilo, Pablo A. and Recht, Benjamin and Tomlin, Claire and Zeilinger, Melanie},
	volume = 	 {120},
	series = 	 {Proceedings of Machine Learning Research},
	month = 	 {10--11 Jun},
	publisher =    {PMLR},
	pdf = 	 {http://proceedings.mlr.press/v120/yang20a/yang20a.pdf},
	url = 	 {https://proceedings.mlr.press/v120/yang20a.html},
	abstract = 	 {Despite the great empirical success of deep reinforcement learning, its theoretical foundation is less well understood. In this work, we make the first attempt to theoretically understand the deep Q-network (DQN) algorithm (Mnih et al., 2015) from both algorithmic and statistical perspectives. In specific, we focus on the fitted Q iteration (FQI) algorithm with deep neural networks, which is a slight simplification of DQN that captures the tricks of experience replay and target network used in DQN. Under mild assumptions, we establish the algorithmic and statistical rates of convergence for the action-value functions of the iterative policy sequence obtained by FQI. In particular, the statistical error characterizes the bias and variance that arise from approximating the action-value function using deep neural network, while the algorithmic error converges to zero at a geometric rate. As a byproduct, our analysis provides justifications for the techniques of experience replay and target network, which are crucial to the empirical success of DQN. Furthermore, as a simple extension of DQN, we propose the Minimax-DQN algorithm for zero-sum Markov game with two players, which is deferred to the appendix due to space limitations.}
}

@article{stable-baselines3,
	author  = {Antonin Raffin and Ashley Hill and Adam Gleave and Anssi Kanervisto and Maximilian Ernestus and Noah Dormann},
	title   = {Stable-Baselines3: Reliable Reinforcement Learning Implementations},
	journal = {Journal of Machine Learning Research},
	year    = {2021},
	volume  = {22},
	number  = {268},
	pages   = {1-8},
	url     = {http://jmlr.org/papers/v22/20-1364.html}
}

@article{10.1063/1.1144830,
	author = {Bishop, Chris M.},
	title = "{Neural networks and their applications}",
	journal = {Review of Scientific Instruments},
	volume = {65},
	number = {6},
	pages = {1803-1832},
	year = {1994},
	month = {06},
	abstract = "{Neural networks provide a range of powerful new techniques for solving problems in pattern recognition, data analysis, and control. They have several notable features including high processing speeds and the ability to learn the solution to a problem from a set of examples. The majority of practical applications of neural networks currently make use of two basic network models. We describe these models in detail and explain the various techniques used to train them. Next we discuss a number of key issues which must be addressed when applying neural networks to practical problems, and highlight several potential pitfalls. Finally, we survey the various classes of problem which may be addressed using neural networks, and we illustrate them with a variety of successful applications drawn from a range of fields. It is intended that this review should be accessible to readers with no previous knowledge of neural networks, and yet also provide new insights for those already making practical use of these techniques.}",
	issn = {0034-6748},
	doi = {10.1063/1.1144830},
	url = {https://doi.org/10.1063/1.1144830},
	eprint = {https://pubs.aip.org/aip/rsi/article-pdf/65/6/1803/8387807/1803\_1\_online.pdf},
}

@article{mcculloch1943logical,
	title={A logical calculus of the ideas immanent in nervous activity},
	author={McCulloch, Warren S and Pitts, Walter},
	journal={The bulletin of mathematical biophysics},
	volume={5},
	pages={115--133},
	year={1943},
	publisher={Springer}
}

@article{sharma2017activation,
	title={Activation functions in neural networks},
	author={Sharma, Sagar and Sharma, Simone and Athaiya, Anidhya},
	journal={Towards Data Sci},
	volume={6},
	number={12},
	pages={310--316},
	year={2017}
}

@MISC{coumans2021,
	author =   {Erwin Coumans and Yunfei Bai},
	title =    {PyBullet, a Python module for physics simulation for games, robotics and machine learning},
	howpublished = {\url{http://pybullet.org}},
	year = {2016--2021}
}

@INPROCEEDINGS{panerati2021learning,
	title={Learning to Fly---a Gym Environment with PyBullet Physics for Reinforcement Learning of Multi-agent Quadcopter Control}, 
	author={Jacopo Panerati and Hehui Zheng and SiQi Zhou and James Xu and Amanda Prorok and Angela P. Schoellig},
	booktitle={2021 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
	year={2021},
	volume={},
	number={},
	pages={},
	doi={}
}

@article{schulman2017proximal,
	title={Proximal policy optimization algorithms},
	author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
	journal={arXiv preprint arXiv:1707.06347},
	year={2017}
}





